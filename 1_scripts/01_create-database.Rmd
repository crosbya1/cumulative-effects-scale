---
title: "Big Grid Database"
author: "Andrew Crosby"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_knit$set(root.dir = normalizePath(".."))  #Sets the working directory to the project folder
```


```{r}

rm(list=ls(all=TRUE)) 
gc()

library(tidyr)
library(stringr)
library(data.table)
library(lubridate)
library(maptools)
library(dplyr)
library(sqldf)
library(reshape2)
library(rgdal)
library(rgeos)
library(raster)
library(ggplot2)
library(sf)

```


Bring in the bird data and format for individual stations (ss), count number of surveys
```{r}
# Load the bird data
birds <- read.csv(file = "0_data/raw/7_birdspervisit_visitparsed_filtereddatetime_asofNov5.csv", header = TRUE)

# Create the ss file
bg_ss_all <- data.table(birds[, c("Project", "Gridnum", "StationNum", "StationKey", "SS", "latitude", "longitude")])
bg_ss <- bg_ss_all[!duplicated(bg_ss_all$StationKey), ]
which(duplicated(bg_ss, by = "StationKey"))
which(duplicated(bg_ss, by = "SS"))

# Convert dates to Julian day  
DD <- with(birds, paste0(Year, "-", Month, "-", Day, " ", Hour, ":", Minute, ":00"))
DD <- strptime(DD, "%Y-%m-%e %H:%M:%S")
## Julian day
birds$julian <- yday(DD) # this is kept as original
birds$jday <- yday(DD)/365
summary(birds$julian)
```



Calculate the time since sunrise 
```{r}
## TSSR = time since sunrise
Coor <- as.matrix(cbind(as.numeric(bg_ss$longitude),as.numeric(bg_ss$latitude)))[match(birds$StationKey, bg_ss$StationKey),]
JL <- as.POSIXct(DD)
subset <- rowSums(is.na(Coor))==0 & !is.na(JL)
sr <- sunriset(Coor[subset,], JL[subset], direction="sunrise", POSIXct.out=FALSE) * 24
birds$srise <- NA
birds$srise[subset] <- sr
birds$start_time <- birds$Hour + birds$Minute/60
birds$tssr <- (birds$start_time - birds$srise) 



```


Remove duplicated surveys and set the survey-specific pcode
```{r}

birds$ss_year <- as.factor(paste0(birds$StationKey, "-", birds$Year))
birds$ss_year_day <- as.factor(paste0(birds$StationKey, "-", birds$Year, "-", birds$julian))

# Remove duplicates
birds2 <- droplevels(birds[!duplicated(c(birds$ss_year_day)), ])
length(which(duplicated(birds2$ss_year_day)))

# Check for duplicates
t.1 <- sqldf("SELECT ss_year_day, COUNT((ss_year_day)) ncount FROM birds2 GROUP BY ss_year_day")
length(which(t.1$ncount > 1)) # should be 0

# Number the individual surveys within each year
birds2$survey <- NA
for(i in 1:nlevels(birds2$ss_year)){
  n <- which(as.numeric(birds2$ss_year) == i)
  d <- cbind(birds2[n, ], n) %>% arrange(julian)
  d$sv <- seq(nrow(d))
  birds2$survey[d$n] <- d$sv
}
 

birds2$pcode <- paste0(birds2$StationKey, "-", birds2$Year, "-", birds2$survey)

# Create the pcode table
bg_pcode <- data.table(birds2[, c("X.1", "StationKey", "latitude", "longitude", "Year", "recording_date", "recording_time", "Month", "Day", "Hour", "Minute", "Second", "julian", "jday", "srise", "start_time", "tssr", "ss_year", "ss_year_day", "pcode", "survey")])


```

For stations surveyed in multiple years, choose the latest year of surveys to use in the analyses
```{r}

max_year <- function(x){
  n <- which(as.numeric(as.factor(bg_pcode$StationKey)) == x)
  d <- bg_pcode[n, ]
  if(nlevels(as.factor(d$Year)) > 1){
    d.1 <- d[which(d$Year == max(d$Year)), ]
  }else{
    d.1 <- d
  }
  return(d.1)
}

bg_maxyear <- droplevels(rbindlist(lapply(1:nlevels(as.factor(bg_pcode$StationKey)), max_year)))


which(duplicated(bg_maxyear, by = "ss_year_day"))



```

Create a table of the number of surveys at each station, match the birds data table to the bg_maxyear table, and create pcode x species table of counts 
```{r}

bg_nsurv <- sqldf("SELECT StationKey, ss_year, COUNT((ss_year)) nsurv FROM bg_maxyear GROUP BY ss_year")
table(as.factor(bg_nsurv$nsurv))


bg_nsurv <- bg_nsurv[match(bg_ss$StationKey, bg_nsurv$StationKey), ]
all.equal(bg_nsurv$StationKey, bg_ss$StationKey)


birds_maxyear <- birds2[match(bg_maxyear$pcode, birds2$pcode), ]
all.equal(bg_maxyear$pcode, birds_maxyear$pcode)

bg_counts <- birds_maxyear[, c(238, 253:254, 18:233)]

all.equal(bg_counts$StationKey, bg_maxyear$StationKey)
all.equal(bg_counts$pcode, bg_maxyear$pcode)

getwd()

save(bg_ss, bg_counts, bg_maxyear, bg_nsurv, file = "0_data/processed/big-grid-ptcount-data-package1.Rdata")

```


Now do the environmental data 

Write a function to extract the desired variables at different scales (150 and 300) and different years(2016 and 2017). 
```{r}

env_data <- function(veg, ss, rad) { 

# Match the vegetation data to the SS data and remove the aggregation grid numbers
veg_ss<- sqldf("SELECT b.StationKey, a.* FROM veg a JOIN ss b ON a.SS = b.SS")
veg_ss <- veg_ss[, 1:which(colnames(veg_ss) == "CCSpruce4")]


# Get the proportion of area in each forest type
type <- c("Decid", "Mixedwood", "Pine", "Spruce", "TreedBog", "TreedFen", "TreedSwamp")

# Create a list of the column numbers containing each forest type (across all age classes)
p.1 <- list()
for(i in 1:base::length(type)){
  r <- list()
  t <- type[i] 
  s <- 1
  for(j in 1:ncol(veg_ss)){
    c <- colnames(veg_ss)[j] 
    if(substr(c, 1, nchar(t)) == type[i] | substr(c, 3, (nchar(t) + 2)) == type[i]){
      r[[(s)]] <- j
    }else{
      next
    }
    s <- s + 1
  }
  p.1[[i]] <- r
}

# Sum areas of all the age classes for each forest type and divide by the area around each point (called rad)
type.mat <- matrix(0, nrow(veg_ss), length(type))
for(i in 1:ncol(type.mat)){
  type.mat[, i] <- rowSums(veg_ss[, unlist(p.1[[i]])])/rad
}

colnames(type.mat) <- type
rownames(type.mat) <- veg_ss$StationKey

# Calculate the proportion of area in each category
prop.con <- rowSums(type.mat[, 3:7])
prop.upCon <- rowSums(type.mat[, 3:4])
prop.lowCon <- rowSums(type.mat[, 5:7])
prop.decid <- type.mat[, 1]
prop.mixed <- type.mat[, 2]
prop.pine <- type.mat[, 3]
prop.spruce <- type.mat[, 4]
prop.Bspr <- type.mat[, 5]
prop.larch <- rowSums(type.mat[, 6:7])
total.for <- rowSums(type.mat)
total.upland.for <- rowSums(type.mat[, 1:4])


# # Calculate weighted mean forest age around each point 
age <- c(4.5, 10, 20, 40, 60, 80, 100, 120, 140, 160)
age.des <- c("R", 1:9)

# get the column numbers for each age class
p <- list()
for(i in 1:length(age.des)){
  t <- list()
  s <- 1
  for(j in 1:ncol(veg_ss)){
    c <- colnames(veg_ss)[j]
    if(substr(c, nchar(c), nchar(c)) == age.des[i]){
      t[[(s)]] <- j
    }else{
      next
    }
    s <- s + 1
  }
  p[[i]] <- t
}


# create a matrix with the proportion of forested area for each age class
age.mat <- matrix(0, nrow(veg_ss), length(age))
for(i in 1:ncol(age.mat)){
  age.mat[, i] <- rowSums(veg_ss[, unlist(p[[i]])])/(total.for*rad)
  age.mat [, i][is.na(age.mat[, i])] <- 0
}

# Multiply the proportional area of each age class by the age classes and sum (using inner product) to get the weighted mean age
wt_mean_age <- age.mat %*% age
rownames(wt_mean_age) <- veg_ss$StationKey
colnames(wt_mean_age) <- "wt_mean_age"



# Calculate the area of each lowland type and sum to get total lowland area 
low <- c("GraminoidFen", "Marsh", "ShrubbyBog", "ShrubbyFen", "ShrubbySwamp", "Water")


p.2 <- list()
for(i in 1:length(low)){
  r <- list()
  t <- low[i] 
  s <- 1
  for(j in 1:ncol(veg_ss)){
    c <- colnames(veg_ss)[j] 
    if(substr(c, 1, nchar(t)) == low[i]){
      r[[(s)]] <- j
    }else{
      next
    }
    s <- s + 1
  }
  p.2[[i]] <- r
}

low.mat <- matrix(0, nrow(veg_ss), length(low))
for(i in 1:ncol(low.mat)){
  d <- as.matrix(veg_ss[, unlist(p.2[[i]])])
  if(ncol(d) == 1){
    low.mat[, i] <- d/rad
  }else{
    low.mat[, i] <- rowSums(d)/rad
  }
}
colnames(low.mat) <- low
rownames(low.mat) <- veg_ss$StationKey

prop.low <- as.matrix(rowSums(low.mat))
rownames(prop.low) <- veg_ss$StationKey
colnames(prop.low) <- "prop.low"


# Calculate the proportional area of open habitats 
open <- c("GrassHerb", "Shrub", "Bare")

p.3 <- list()
for(i in 1:length(open)){
  r <- list()
  t <- open[i] 
  s <- 1
  for(j in 1:ncol(veg_ss)){
    c <- colnames(veg_ss)[j] 
    if(c == open[i]){
      r[[(s)]] <- j
    }else{
      next
    }
    s <- s + 1
  }
  p.3[[i]] <- r
}

open.mat <- matrix(0, nrow(veg_ss), length(open))
for(i in 1:ncol(open.mat)){
  d <- as.matrix(veg_ss[, unlist(p.3[[i]])])
  if(ncol(d) == 1){
    open.mat[, i] <- d/rad
  }else{
    open.mat[, i] <- rowSums(d)/rad
  }
}
colnames(open.mat) <- open
rownames(open.mat) <- veg_ss$StationKey

prop.open <- as.matrix(rowSums(open.mat))
rownames(prop.open) <- veg_ss$StationKey
colnames(prop.open) <- "prop.open"

all.equal(rownames(wt_mean_age), names(prop.con), names(prop.mixed), names(prop.decid))

veg_data <- data.frame(wt_mean_age = wt_mean_age, prop.con = prop.con, prop.upCon = prop.upCon, prop.lowCon = prop.lowCon, prop.decid = prop.decid, prop.mixed = prop.mixed, prop.pine = prop.pine, prop.spruce = prop.spruce, prop.Bspr = prop.Bspr, prop.larch = prop.larch, total.for, prop.low, total.upland.for, prop.open)

return(veg_data)

  }

```


```{r}

veghf_150_2017 <- read.csv(file = "0_data/raw/10_vegHF150mscale_2017_stationgridassignment.csv", header = TRUE)
veg_150_2017 <- env_data(veghf_150_2017, bg_ss, rad = pi*150^2)

veghf_150_2016 <- read.csv(file = "0_data/raw/10_vegHF150mscale_2016_stationgridassignment.csv", header = TRUE)
veg_150_2016 <- env_data(veghf_150_2016, bg_ss, rad = pi*150^2)



veghf_300_2016 <- read.csv(file = "0_data/raw/10_vegHF36000m2scale_2016_stationgridassignment.csv", header = TRUE)

veg_300_2016 <- env_data(veghf_300_2016, bg_ss, rad = 600^2)

veghf_300_2017 <- read.csv(file = "0_data/raw/10_vegHF36000m2scale_2017_stationgridassignment.csv", header = TRUE)

veg_300_2017 <- env_data(veghf_300_2017, bg_ss, rad = 600^2)

save(veg_150_2016, veg_150_2017, veg_300_2016, veg_300_2017, file = "0_data/processed/big-grid-veg-point.Rdata")



```



Now the human footprint data 


```{r}



sum.point <- function(vars, veg_ss, rad, name){
p <- list()
for(i in 1:length(vars)){
  r <- list()
  t <- vars[i] 
  s <- 1
  for(j in 1:ncol(veg_ss)){
    c <- colnames(veg_ss)[j] 
    if(substr(c, 1, nchar(t)) == vars[i]){
      r[[(s)]] <- j
    }else{
      next
    }
    s <- s + 1
  }
  p[[i]] <- r
}

mat <- matrix(0, nrow(veg_ss), length(vars))
for(i in 1:ncol(mat)){
  d <- as.matrix(veg_ss[, unlist(p[[i]])])
  if(ncol(d) == 1){
    mat[, i] <- d/rad
  }else{
    mat[, i] <- rowSums(d)/rad
  }
}
colnames(mat) <- vars
rownames(mat) <- veg_ss$StationKey

prop <- as.matrix(rowSums(mat))
rownames(prop) <- veg_ss$StationKey
colnames(prop) <- paste0("prop.", name)

return(prop)

}


sum.point.scale <- function(varlist, veg_hf, ss, rad, namelist){
  
  veg_ss <- sqldf("SELECT b.StationKey, a.* FROM veg_hf a JOIN ss b ON a.SS = b.SS")

  d.var <- list()
  for(i in 1:length(varlist)){
    d.var[[i]] <- sum.point(varlist[[i]], veg_ss, rad, namelist[[i]])
    
  }
  t <- as.data.frame(do.call(cbind, d.var)) 
  t$total.hf <- rowSums(t)
  t.1 <- t
  for(i in 1:nrow(t)){
    for(j in 1:ncol(t)){
      t.1[i, j] <- ifelse(t[i, j] > 1, 1, t[i, j])
    }
  }  
  return(t.1)
}


softlin <- c("SeismicLineNarrow", "SeismicLineWide", "Pipeline", "TransmissionLine", "RoadTrailVegetated", "RoadVegetatedVerge", "RailVegetatedVerge")
softpoly <- c("OtherDisturbedVegetation", "WellSite")
hardlin <- c("RoadHardSurface", "RailHardSurface")
hardpoly <- c("CultivationAbandoned", "CultivationRoughPasture", "CultivationTamePasture", "HighDensityLivestockOperation", "BorrowpitsDugoutsSumps", "MunicipalWaterSewage", "Reservoirs", "Canals", "UrbanIndustrial", "UrbanResidence", "RuralResidentialIndustrial", "IndustrialSiteRural", "WindGenerationFacility", "MineSite", "PeatMine")


hf150_2016 <- sum.point.scale(varlist = list(softlin, softpoly, hardlin, hardpoly), veg_hf = veghf_150_2016, ss = bg_ss, rad = pi*150^2, namelist = c("softlin", "softpoly", "hardlin", "hardpoly"))
hf150_2017 <- sum.point.scale(varlist = list(softlin, softpoly, hardlin, hardpoly), veg_hf = veghf_150_2017, ss = bg_ss, rad = pi*150^2, namelist = c("softlin", "softpoly", "hardlin", "hardpoly"))


hf300_2016 <- sum.point.scale(varlist = list(softlin, softpoly, hardlin, hardpoly), veg_hf = veghf_300_2016, ss = bg_ss, rad = 600^2, namelist = c("softlin", "softpoly", "hardlin", "hardpoly"))
head(hf300_2016)

hf300_2017 <- sum.point.scale(varlist = list(softlin, softpoly, hardlin, hardpoly), veg_hf = veghf_300_2017, ss = bg_ss, rad = 600^2, namelist = c("softlin", "softpoly", "hardlin", "hardpoly"))
head(hf300_2016)


save(hf150_2016, hf150_2017, hf300_2016, hf300_2017, file = "0_data/processed/big-grid-hf-point.Rdata")


```


Put it together into an analysis package 
```{r}
# Get the subset of the bird data for which there is vegetation data
bg_count_veg <- bg_counts[which(bg_counts$StationKey %in% rownames(veg_300_2016)), ]
bg_nsurv_veg <- bg_nsurv[which(bg_nsurv$StationKey %in% rownames(veg_300_2016)), ]
bg_nsurv_veg$nsurv <- ifelse(bg_nsurv_veg$nsurv > 4, 4, bg_nsurv_veg$nsurv)           # Use only the first 4 surveys
bg_maxyear_veg <- bg_maxyear[which(bg_maxyear$StationKey %in% rownames(veg_300_2016)), ]
bg_ss_veg <- bg_ss[match(bg_nsurv_veg$StationKey, bg_ss$StationKey), ]

# Convert counts to point counts
bg_pa <- data.frame(bg_count_veg[, 1:2], ifelse(bg_count_veg[, 4:219] > 0, 1, 0))


# Get the ovenbird data to use in matching vegetation years to survey years
oven_point <- bg_pa[, c(1:2, which(colnames(bg_pa) =="OVEN"))]

oven_pt <- oven_point %>% spread(survey, OVEN)
oven_pt <- oven_pt[match(bg_nsurv_veg$StationKey, oven_pt$StationKey), 1:5]
head(oven_pt)
all.equal(oven_pt$StationKey, bg_nsurv_veg$StationKey)


# Get the year in which each survey was done
data.year <- sqldf::sqldf("SELECT DISTINCT StationKey, Year FROM bg_maxyear_veg;")
data.year <- data.year[match(oven_pt$StationKey, data.year$StationKey), ]
all.equal(data.year$StationKey, oven_pt$StationKey)


# Write the function to match the veg  and hf data to the survey years
veg_year <- function(i, v2016, v2017, hf2016, hf2017){
  if(data.year$Year[i] <= 2016){
    v <- data.frame(c(v2016[which(rownames(v2016) == data.year$StationKey[i]), ], hf2016[which(rownames(hf2016) == data.year$StationKey[i]), ]))
  }else{
    v <- data.frame(c(v2017[which(rownames(v2017) == data.year$StationKey[i]), ], hf2017[which(rownames(hf2017) == data.year$StationKey[i]), ]))
  }
  return(unlist(v))
}

veg_year(1, veg_300_2016, veg_300_2017, hf300_2016, hf300_2017)

# Make the 300 meter dataset
veghf_300 <- data.frame(t(sapply(1:nrow(data.year), veg_year, v2016 = veg_300_2016, v2017 = veg_300_2017, hf2016 = hf300_2016, hf2017 = hf300_2017)))
rownames(veghf_300) <- data.year$StationKey
all.equal(rownames(veghf_300), oven_pt$StationKey)



# Create datasets at different scales around the points
veghf_150 <- data.frame(t(sapply(1:nrow(data.year), veg_year, v2016 = veg_150_2016, v2017 = veg_150_2017, hf2016 = hf150_2016, hf2017 = hf150_2017)))
rownames(veghf_150) <- data.year$StationKey
all.equal(rownames(veghf_150), oven_pt$StationKey)

veg_150_hf_300 <- data.frame(t(sapply(1:nrow(data.year), veg_year, v2016 = veg_150_2016, v2017 = veg_150_2017, hf2016 = hf300_2016, hf2017 = hf300_2017)))
rownames(veg_150_hf_300) <- data.year$StationKey
all.equal(rownames(veg_150_hf_300), oven_pt$StationKey)

veg_300_hf_150 <- data.frame(t(sapply(1:nrow(data.year), veg_year, v2016 = veg_300_2016, v2017 = veg_300_2017, hf2016 = hf150_2016, hf2017 = hf150_2017)))
rownames(veg_150_hf_300) <- data.year$StationKey
all.equal(rownames(veg_150_hf_300), oven_pt$StationKey)


# Get the survey variables and put into a site x survey x variable array
det.var.raw <- data.frame(bg_maxyear_veg[, c("StationKey", "survey")], int = rep(1, nrow(bg_maxyear_veg)), jday = scale(bg_maxyear_veg$julian), tssr = scale(bg_maxyear_veg$tssr), jday2 = scale(bg_maxyear_veg$julian^2))

det.var.scale <- det.var.raw[-which(det.var.raw$survey > 4), ]

det.var.m <- reshape2::melt(det.var.scale, id = c("StationKey", "survey"))

det.var_veg<- acast(det.var.m, StationKey ~ survey ~ variable)
det.var_veg <- det.var_veg[match(bg_nsurv_veg$StationKey, rownames(det.var_veg)), , ]
all.equal(rownames(det.var_veg), bg_nsurv_veg$StationKey, oven_pt$StationKey, rownames(veghf_300))

all.equal(data.year$StationKey, rownames(det.var_veg))



save(bg_count_veg, bg_maxyear_veg, bg_nsurv_veg, bg_pa, bg_ss_veg, data.year, veghf_300, veghf_150, veg_150_hf_300, veg_300_hf_150, det.var_veg, file = "0_data/processed/big-grid-point-data.Rdata")



```



Create spatial database
```{r}

ab <- readOGR(dsn = "0_data/raw/shapefiles", layer = "Alberta_epsg3400")
ab.sf <- st_as_sf(ab)

epsg <- make_EPSG()
p <- epsg %>% filter(code == 4326)

ss_veg.sp <- SpatialPointsDataFrame(coords = bg_ss_veg[, c("longitude", "latitude")], data = bg_ss_veg[, c("Gridnum", "StationNum", "StationKey", "SS")], proj4string = CRS(p$prj4))

ss_veg_sf <- st_transform(st_as_sf(ss_veg.sp), crs = st_crs(ab.sf))

plot((ss_veg_sf %>% filter(Gridnum == 2))$geometry)


```





Check to see if models come out as expected
```{r}

oven_count <- bg_count_veg[, c(1,2, which(colnames(bg_count_veg) == "OVEN"))]

oven_ct <- oven_count %>% spread(survey, OVEN)
oven_ct <- oven_ct[match(bg_nsurv_veg$StationKey, oven_ct$StationKey), 1:5]
head(oven_ct)
all.equal(oven_ct$StationKey, bg_nsurv_veg$StationKey)


oven.try <- apply(oven_ct[, -1], 1, max, na.rm = TRUE)

summary(glm(oven.try ~ 1, family = "poisson"))
summary(glm(oven.try ~ veghf_300$prop.decid, family = "poisson"))
summary(glm(oven.try ~ veghf_300$wt_mean_age + veghf_300$prop.decid, family = "poisson"))

oven.try2 <- apply(oven_pt[, -1], 1, max, na.rm = TRUE)
summary(glm(oven.try2 ~ 1, family = "binomial"))
summary(glm(oven.try2 ~ veghf_300$prop.decid, family = "binomial"))
summary(glm(oven.try2 ~ veghf_300$wt_mean_age + veghf_300$prop.decid, family = "binomial"))
summary(glm(oven.try2 ~ veghf_300$wt_mean_age + veghf_300$prop.decid + veghf_300$total.hf, family = "binomial"))

cawa_point <- bg_pa[, c(1:2, which(colnames(bg_pa) =="CAWA"))]

cawa_pt <- cawa_point %>% spread(survey, CAWA)
cawa_pt <- cawa_pt[match(bg_nsurv_veg$StationKey, cawa_pt$StationKey), 1:5]
cawa.try <- apply(cawa_pt[, -1], 1, max, na.rm = TRUE)
summary(glm(cawa.try ~ 1, family = "binomial"))
summary(glm(cawa.try ~ veghf_300$prop.decid, family = "binomial"))
summary(glm(cawa.try ~ veghf_300$wt_mean_age + veghf_300$prop.decid, family = "binomial"))
summary(glm(cawa.try ~ veghf_300$wt_mean_age + veghf_300$prop.decid + veghf_300$total.hf, family = "binomial"))

```










Summarize at different scales 
```{r}

gridnum <- sqldf("SELECT b.StationKey, b.Gridnum, a.g2x2, a.g3x3, a.g4x4, a.g5x5 FROM veghf_300_2016 a JOIN bg_ss b ON a.SS = b.SS")

gridID <- data.frame(gridnum$StationKey, gridnum$Gridnum, t(sapply(1:nrow(gridnum), function(x){sapply(3:6, function(j) paste0(gridnum$Gridnum[x], "-", gridnum[x, j]))})))
colnames(gridID) <- colnames(gridnum)

veg_hf_sum <- function(veg_origin, veg, hf, ss, gridID, rad, gridsize){
  veg_ss<- sqldf("SELECT b.StationKey, a.* FROM veg_origin a JOIN ss b ON a.SS = b.SS")
  
  veg_ss <- veg_ss[, 1:which(colnames(veg_ss) == "CCSpruce4")]
  all.equal(veg_ss$StationKey, gridID$StationKey, rownames(veg))
  
  
  
  age <- c(4.5, 10, 20, 40, 60, 80, 100, 120, 140, 160) 
  age.des <- c("R", 1:9) 
  
  p <- list() 
  for(i in 1:length(age.des)){ 
    t <- list() 
    s <- 1 
    for(j in 1:ncol(veg_ss)){
 
      c <- colnames(veg_ss)[j] 
      if(substr(c, nchar(c), nchar(c)) == age.des[i]){
        t[[(s)]] <- j
        }else{
          next
          } 
      s <- s + 1 
      } 
    p[[i]] <- t 
  }
  
  age.mat <- data.frame(matrix(0, nrow(veg_ss), length(age)))
  for(i in 1:ncol(age.mat)){
    age.mat[, i] <- rowSums(veg_ss[, unlist(p[[i]])])
    }
  colnames(age.mat) <- age.des
  rownames(age.mat) <- veg_ss$StationKey
  
  gridlist <- list()
  for(i in 3:ncol(gridID)){
    # Sum land cover types in grid 
    d <- ((veg[-1]*rad) %>% group_by(gridID[, i]) %>% summarize_at(colnames(veg[-1]), list(sum = sum)))
    
    colnames(d)[-1] <- substr(colnames(d)[-1], 1, nchar(colnames(d)[-1]) - 4) # Remove "_sum" from column names
    
    n <- which(sapply(1:nrow(d), function(x) if_else(substr(d$`gridID[, i]`[x], nchar(d$`gridID[, i]`[x]) - 1, nchar(d$`gridID[, i]`[x])) == "-0", 0, 1)) == 1)
    d.2 <- d[n, ]
    
    age.gr <- ((age.mat) %>% group_by(gridID[, i]) %>% summarize_at(colnames(age.mat), list(sum = sum)))[, -1]/d$total.for
    age.grid <- age.gr[n, ]
    wt_mean_age <- as.matrix(age.grid) %*% age
    rownames(wt_mean_age) <- d.2$`gridID[, i]`
    colnames(wt_mean_age) <- "wt_mean_age"
    
    d.3 <- data.frame(wt_mean_age, d.2[, -1]/(rad*gridsize[i-2]))
    
    d.4 <- ((hf*rad) %>% group_by(gridID[, i]) %>% summarize_at(colnames(hf), list(sum = sum)))
    colnames(d.4)[-1] <- substr(colnames(d.4)[-1], 1, nchar(colnames(d.4)[-1]) - 4) # Remove "_sum" from column names
    d.4.1 <- d.4[n, ][, -1]/(rad*gridsize[i-2])
    rownames(d.4.1) <- d.4$`gridID[, i]`[n]
    
    t <- data.frame(gridID = d.2$`gridID[, i]`) 
    t1 <- data.frame(gID = gridID[, i], gnum = gridID[, 2])
    gnum <-  sqldf("SELECT DISTINCT a.gridID, b.gnum FROM t a JOIN t1 b ON a.gridID = b.gID")
    
    gridlist[[i - 2]] <- cbind(gnum, d.3, d.4.1)
    ifelse(all.equal(rownames(d.3), gnum$gridID, rownames(d.4.1), gridlist[[i - 2]]$gridID), next, break)

  } 
  return(gridlist)
}

veg_origin <- veghf_300_2016
veg = veg_300_2016
rad = 600^2

hf = hf300_2016
ss = bg_ss
gridsize = c(4, 9, 16, 25)



grids2016 <- veg_hf_sum(veg_origin = veghf_300_2016, veg = veg_300_2016, hf = hf300_2016, gridID = gridID, rad = 600^2, ss = bg_ss, gridsize = c(4, 9, 16, 25))
grids2017 <- veg_hf_sum(veg_origin = veghf_300_2017, veg = veg_300_2017, hf = hf300_2017, gridID = gridID, rad = 600^2, ss = bg_ss, gridsize = c(4, 9, 16, 25))




```



```{r}

grid_year <- sqldf("SELECT DISTINCT b.Gridnum, MAX(a.Year) grid_year FROM bg_maxyear_veg a JOIN gridnum b ON a.StationKey = b.StationKey GROUP BY Gridnum")
head(grid_year)
length(which(grid_year$`COUNT(Year)` > 1))

a <- grids2016
b <- grids2017

gridsize = c(4, 9, 16, 25)

grids_veghf <- list()
for(i in 1:length(gridsize)){
  d <- a[[i]]$gnum
  e <- do.call(rbind, lapply(1:length(d), function(x) if(grid_year[which(grid_year$Gridnum == d[x]), "grid_year"] <= 2016){a[[i]][x, ]}else{b[[i]][x, ]}))
  grids_veghf[[i]] <- e
}


save(grids2016, grids2017, grids_veghf, gridID, file = "0_data/processed/big-grid-veghf-grids.Rdata")

```














